{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HandWriteRecoginiton.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQWIoqplqOj7"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xisXJI8sqOj-"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow.keras.utils as tku"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E6bbUy3qOkA",
        "outputId": "e0f3cee8-c758-4b90-e722-19f0c61a3f71"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NVtZhS1qOkC",
        "outputId": "3a7d9dcd-e347-45ad-e259-0d8969dbf088"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/home/jovyan/binder/MNIST/training_set',\n",
        "                                                 target_size = (28, 28),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 37340 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiemCdZ-qOkE",
        "outputId": "b2a32f6d-6cb9-4f9e-b23d-77221c484660"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "test_set = train_datagen.flow_from_directory('/home/jovyan/binder/MNIST/test_set',\n",
        "                                                 target_size = (28, 28),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4660 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28lKskOgqOkF"
      },
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3y7loBRqOkG"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[28, 28, 3]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj9Y9p63qOkI"
      },
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9-oxSNiqOkL"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnzd0ToPqOkP"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA9XcJXHqOkQ"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=64, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtRC18HDqOkT"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0w5A1t5qOkU"
      },
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taOqbh3uqOkV",
        "outputId": "303aebba-4fcc-4785-b196-b6c549450e29"
      },
      "source": [
        "trained_model = cnn.fit(x = training_set, validation_data = test_set, epochs = 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1167/1167 [==============================] - 96s 81ms/step - loss: 0.3725 - accuracy: 0.8785 - val_loss: 0.1686 - val_accuracy: 0.9464\n",
            "Epoch 2/20\n",
            "1167/1167 [==============================] - 95s 81ms/step - loss: 0.1359 - accuracy: 0.9580 - val_loss: 0.1141 - val_accuracy: 0.9635\n",
            "Epoch 3/20\n",
            "1167/1167 [==============================] - 95s 81ms/step - loss: 0.1043 - accuracy: 0.9677 - val_loss: 0.0823 - val_accuracy: 0.9738\n",
            "Epoch 4/20\n",
            "1167/1167 [==============================] - 103s 88ms/step - loss: 0.0865 - accuracy: 0.9725 - val_loss: 0.0760 - val_accuracy: 0.9770\n",
            "Epoch 5/20\n",
            "1167/1167 [==============================] - 98s 84ms/step - loss: 0.0770 - accuracy: 0.9755 - val_loss: 0.0635 - val_accuracy: 0.9796\n",
            "Epoch 6/20\n",
            "1167/1167 [==============================] - 98s 84ms/step - loss: 0.0631 - accuracy: 0.9798 - val_loss: 0.0673 - val_accuracy: 0.9775\n",
            "Epoch 7/20\n",
            "1167/1167 [==============================] - 103s 88ms/step - loss: 0.0623 - accuracy: 0.9804 - val_loss: 0.0561 - val_accuracy: 0.9824\n",
            "Epoch 8/20\n",
            "1167/1167 [==============================] - 101s 87ms/step - loss: 0.0555 - accuracy: 0.9825 - val_loss: 0.0667 - val_accuracy: 0.9796\n",
            "Epoch 9/20\n",
            "1167/1167 [==============================] - 100s 86ms/step - loss: 0.0520 - accuracy: 0.9834 - val_loss: 0.0658 - val_accuracy: 0.9792\n",
            "Epoch 10/20\n",
            "1167/1167 [==============================] - 163s 140ms/step - loss: 0.0471 - accuracy: 0.9849 - val_loss: 0.0592 - val_accuracy: 0.9843\n",
            "Epoch 11/20\n",
            "1167/1167 [==============================] - 94s 81ms/step - loss: 0.0465 - accuracy: 0.9852 - val_loss: 0.0640 - val_accuracy: 0.9788\n",
            "Epoch 12/20\n",
            "1167/1167 [==============================] - 98s 84ms/step - loss: 0.0424 - accuracy: 0.9864 - val_loss: 0.0599 - val_accuracy: 0.9822\n",
            "Epoch 13/20\n",
            "1167/1167 [==============================] - 92s 79ms/step - loss: 0.0387 - accuracy: 0.9877 - val_loss: 0.0606 - val_accuracy: 0.9828\n",
            "Epoch 14/20\n",
            "1167/1167 [==============================] - 92s 79ms/step - loss: 0.0377 - accuracy: 0.9875 - val_loss: 0.0496 - val_accuracy: 0.9837\n",
            "Epoch 15/20\n",
            "1167/1167 [==============================] - 92s 79ms/step - loss: 0.0345 - accuracy: 0.9885 - val_loss: 0.0628 - val_accuracy: 0.9792\n",
            "Epoch 16/20\n",
            "1167/1167 [==============================] - 94s 80ms/step - loss: 0.0347 - accuracy: 0.9881 - val_loss: 0.0570 - val_accuracy: 0.9809\n",
            "Epoch 17/20\n",
            "1167/1167 [==============================] - 92s 79ms/step - loss: 0.0339 - accuracy: 0.9890 - val_loss: 0.0510 - val_accuracy: 0.9845\n",
            "Epoch 18/20\n",
            "1167/1167 [==============================] - 91s 78ms/step - loss: 0.0296 - accuracy: 0.9910 - val_loss: 0.0528 - val_accuracy: 0.9843\n",
            "Epoch 19/20\n",
            "1167/1167 [==============================] - 91s 78ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 0.0541 - val_accuracy: 0.9841\n",
            "Epoch 20/20\n",
            "1167/1167 [==============================] - 92s 79ms/step - loss: 0.0289 - accuracy: 0.9903 - val_loss: 0.0630 - val_accuracy: 0.9830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTfWTaFIqOkW"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/home/jovyan/binder/MNIST/single_prediction/img_11.jpg', target_size = (28, 28))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "results = (cnn.predict(test_image))\n",
        "training_set.class_indices\n",
        "if results[0][0] == 1:\n",
        "  prediction = 'Zero'\n",
        "elif results[0][1] == 1:\n",
        "  prediction = 'One'\n",
        "elif results[0][2] == 1:\n",
        "  prediction = 'Two'\n",
        "elif results[0][3] == 1:\n",
        "  prediction = 'Three'\n",
        "elif results[0][4] == 1:\n",
        "  prediction = 'Four'\n",
        "elif results[0][5] == 1:\n",
        "  prediction = 'Five'\n",
        "elif results[0][6] == 1:\n",
        "  prediction = 'Six'\n",
        "elif results[0][7] == 1:\n",
        "  prediction = 'Seven'\n",
        "elif results[0][8] == 1:\n",
        "  prediction = 'Eight'\n",
        "else:\n",
        "  prediction = 'Nine'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKrHuhrfqOkX",
        "outputId": "c71d3196-a74c-41b4-e36a-9da60ba52fbc"
      },
      "source": [
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMrRac4DqOkY",
        "outputId": "a5b794c9-4cd5-4b50-f6fe-aa0cf27033c1"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Five\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWg400MRqOkZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}